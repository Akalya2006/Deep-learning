{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c1a0be-64f1-4319-8ad1-38a63efc1c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srmmc\\.matplotlib\\IEE\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 34ms/step - accuracy: 0.7617 - loss: 0.4831 - val_accuracy: 0.8402 - val_loss: 0.3566\n",
      "Epoch 2/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.8859 - loss: 0.2787 - val_accuracy: 0.8376 - val_loss: 0.3611\n",
      "Epoch 3/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9183 - loss: 0.2116 - val_accuracy: 0.8482 - val_loss: 0.3785\n",
      "Epoch 4/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.9419 - loss: 0.1570 - val_accuracy: 0.8410 - val_loss: 0.4244\n",
      "Epoch 5/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9606 - loss: 0.1159 - val_accuracy: 0.8338 - val_loss: 0.4846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x285b69a4fe0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import imdb \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Embedding, LSTM, Dense \n",
    "from keras.preprocessing.sequence import pad_sequences \n",
    "# Load dataset \n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000) \n",
    "X_train = pad_sequences(X_train, maxlen=100) \n",
    "X_test = pad_sequences(X_test, maxlen=100) \n",
    "# Model \n",
    "model = Sequential([ \n",
    "Embedding(10000, 32, input_length=100), \n",
    "LSTM(100), \n",
    "Dense(1, activation='sigmoid') \n",
    "]) \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ebafbe6-3b4a-4421-b2fe-da8da073dbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.7643 - loss: 0.4653 - val_accuracy: 0.8356 - val_loss: 0.3740\n",
      "Epoch 2/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.8870 - loss: 0.2802 - val_accuracy: 0.8474 - val_loss: 0.3489\n",
      "Epoch 3/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.9208 - loss: 0.2079 - val_accuracy: 0.8378 - val_loss: 0.4055\n",
      "Epoch 4/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - accuracy: 0.9426 - loss: 0.1582 - val_accuracy: 0.8444 - val_loss: 0.4104\n",
      "Epoch 5/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9583 - loss: 0.1172 - val_accuracy: 0.8382 - val_loss: 0.4801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x285c205cfe0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Embedding, GRU, Dense \n",
    "model = Sequential([ \n",
    "Embedding(10000, 32, input_length=100), \n",
    "GRU(100), \n",
    "Dense(1, activation='sigmoid') \n",
    "]) \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13be01da-00d1-4f10-82a7-b3c285e97de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "Review Text                         LSTM Output     GRU Output      Same?\n",
      "An emotional and deep plot          Positive        Positive        Yes\n",
      "The story was dull                  Negative        Negative        Yes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
    "\n",
    "# Sample review texts\n",
    "texts = [\"An emotional and deep plot\", \"The story was dull\"]\n",
    "labels = [1, 0]  # 1 = Positive, 0 = Negative\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "data = pad_sequences(sequences, maxlen=10)\n",
    "\n",
    "# Parameters\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_dim = 50\n",
    "\n",
    "# LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=10),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstm_model.fit(data, np.array(labels), epochs=10, verbose=0)\n",
    "\n",
    "# GRU Model\n",
    "gru_model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=10),\n",
    "    GRU(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "gru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "gru_model.fit(data, np.array(labels), epochs=10, verbose=0)\n",
    "\n",
    "# Predictions\n",
    "lstm_preds = lstm_model.predict(data)\n",
    "gru_preds = gru_model.predict(data)\n",
    "\n",
    "# Output Comparison\n",
    "print(f\"{'Review Text':<35} {'LSTM Output':<15} {'GRU Output':<15} {'Same?'}\")\n",
    "for i, text in enumerate(texts):\n",
    "    lstm_sentiment = \"Positive\" if lstm_preds[i] > 0.5 else \"Negative\"\n",
    "    gru_sentiment = \"Positive\" if gru_preds[i] > 0.5 else \"Negative\"\n",
    "    same = \"Yes\" if lstm_sentiment == gru_sentiment else \"No\"\n",
    "    print(f\"{text:<35} {lstm_sentiment:<15} {gru_sentiment:<15} {same}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c90c553a-8554-4ada-baf1-0f26cfc1eeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "Review Text                         Actual Sentiment   Predicted Sentiment  Correct (Y/N)\n",
      "I loved the movie, fantastic!       Positive           Negative             N\n",
      "Worst film ever, boring.            Negative           Negative             Y\n",
      "It was okay, not great.             Neutral            Negative             N\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Sample review texts and actual sentiments\n",
    "texts = [\n",
    "    \"I loved the movie, fantastic!\",\n",
    "    \"Worst film ever, boring.\",\n",
    "    \"It was okay, not great.\"\n",
    "]\n",
    "actual_sentiments = [\"Positive\", \"Negative\", \"Neutral\"]\n",
    "\n",
    "# Map actual sentiments to binary labels (Positive=1, Negative=0, Neutral=0.5 for simplicity)\n",
    "# Note: You can refine this with a 3-class model if needed\n",
    "labels = [1, 0, 0]  # Treat Neutral as Negative for binary classification\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "data = pad_sequences(sequences, maxlen=10)\n",
    "\n",
    "# Parameters\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_dim = 50\n",
    "\n",
    "# LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=10),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(data, np.array(labels), epochs=10, verbose=0)\n",
    "\n",
    "# Predictions\n",
    "preds = model.predict(data)\n",
    "\n",
    "# Convert predictions to sentiment labels\n",
    "def get_sentiment(pred):\n",
    "    return \"Positive\" if pred > 0.5 else \"Negative\"\n",
    "\n",
    "# Output Comparison Table\n",
    "print(f\"{'Review Text':<35} {'Actual Sentiment':<18} {'Predicted Sentiment':<20} {'Correct (Y/N)'}\")\n",
    "for i, text in enumerate(texts):\n",
    "    predicted = get_sentiment(preds[i])\n",
    "    correct = \"Y\" if predicted == actual_sentiments[i] else \"N\"\n",
    "    print(f\"{text:<35} {actual_sentiments[i]:<18} {predicted:<20} {correct}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06983f8d-58f1-421a-9f24-7022fa357fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IEE]",
   "language": "python",
   "name": "conda-env-IEE-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
